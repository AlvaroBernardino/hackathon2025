{"cells":[{"cell_type":"code","source":["# Bibliotecas padrão\n","import os\n","from io import BytesIO\n","from datetime import datetime, timedelta\n","from dateutil.relativedelta import relativedelta\n","\n","# Bibliotecas externas\n","import pandas as pd\n","import requests\n","from sqlalchemy import create_engine, inspect, text\n","\n","# PySpark\n","from pyspark.sql import SparkSession\n","from pyspark.sql.types import IntegerType, StringType, FloatType\n","from pyspark.sql.window import Window\n","from pyspark.sql.functions import (\n","    col, lit, row_number, expr, monotonically_increasing_id, \n","    regexp_replace, trim, lower, to_date, date_format, \n","    dayofmonth, month, year, quarter, lag, when, sequence, \n","    explode, count, sum as spark_sum\n",")\n","\n","from pyspark.sql.functions import udf\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"state":"finished","livy_statement_state":"available","session_id":"35b8594a-2d83-472e-8c92-36b1ea22ab25","normalized_state":"finished","queued_time":"2025-06-22T16:51:49.5429856Z","session_start_time":null,"execution_start_time":"2025-06-22T16:51:49.5442397Z","execution_finish_time":"2025-06-22T16:51:49.8565431Z","parent_msg_id":"5d2dac4f-c1e6-40c5-94c6-724fe584b845"},"text/plain":"StatementMeta(, 35b8594a-2d83-472e-8c92-36b1ea22ab25, 11, Finished, Available, Finished)"},"metadata":{}}],"execution_count":9,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f69cf176-5f71-478c-8ffc-d99e0490da87"},{"cell_type":"code","source":["# Dicionários e variáveis\n","path_silver = \"abfss://Hackathon_Emprega_Dados@onelake.dfs.fabric.microsoft.com/lakehouse_vendas.Lakehouse/Files/silver/\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"35b8594a-2d83-472e-8c92-36b1ea22ab25","normalized_state":"finished","queued_time":"2025-06-22T16:49:21.1086191Z","session_start_time":null,"execution_start_time":"2025-06-22T16:49:21.1097699Z","execution_finish_time":"2025-06-22T16:49:21.4063548Z","parent_msg_id":"fd47cac2-54b3-436d-bd82-ee321909b0ba"},"text/plain":"StatementMeta(, 35b8594a-2d83-472e-8c92-36b1ea22ab25, 4, Finished, Available, Finished)"},"metadata":{}}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"91a76b30-f1ce-488d-a1b8-5cb7c73b7a32"},{"cell_type":"code","source":["## Função para converter a coluna de data para o formato id_data\n","def convert_iddata(df, col_name):\n","    return pd.to_datetime(df[col_name], format=\"%Y%m%d\").dt.strftime(\"%Y%m%d\").astype(\"Int64\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"35b8594a-2d83-472e-8c92-36b1ea22ab25","normalized_state":"finished","queued_time":"2025-06-22T16:49:25.6992811Z","session_start_time":null,"execution_start_time":"2025-06-22T16:49:25.7004187Z","execution_finish_time":"2025-06-22T16:49:25.9676525Z","parent_msg_id":"14012440-13a0-45ca-a230-267efe17b90e"},"text/plain":"StatementMeta(, 35b8594a-2d83-472e-8c92-36b1ea22ab25, 5, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ae791049-fe58-443d-855c-ccad6bb86bb6"},{"cell_type":"code","source":["def classificar_despesa(item):\n","    if item in [\n","        'Despesas com matéria-prima',\n","        'Despesas de transporte e logística',\n","        'Mecanicos',\n","        'Manutenção de equipamentos'\n","    ]:\n","        return 'Custos Variáveis (CPV)'\n","\n","    elif item in [\n","        'Despesas com marketing e publicidade',\n","        'Despesas com viagens e deslocamentos',\n","        'Despesas com telefonia móvel e fixa',\n","        'Trafego', 'Google Ads', 'Meta Ads', 'LinkedIn Ads', 'CRM', 'Landin page'\n","    ]:\n","        return 'Despesas Comerciais'\n","\n","    elif item in [\n","        'Impostos e taxas'\n","    ]:\n","        return 'Impostos'\n","\n","    elif item in [\n","        'Treinamento'\n","    ]:\n","        return 'Desenvolvimento Pessoal'\n","\n","    else:\n","        return 'Despesas Administrativas'"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":6,"statement_ids":[6],"state":"finished","livy_statement_state":"available","session_id":"35b8594a-2d83-472e-8c92-36b1ea22ab25","normalized_state":"finished","queued_time":"2025-06-22T16:49:29.5381977Z","session_start_time":null,"execution_start_time":"2025-06-22T16:49:29.5394625Z","execution_finish_time":"2025-06-22T16:49:29.8198021Z","parent_msg_id":"513f792d-d997-418a-8860-bf28191d4802"},"text/plain":"StatementMeta(, 35b8594a-2d83-472e-8c92-36b1ea22ab25, 6, Finished, Available, Finished)"},"metadata":{}}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"15b20ec4-a6de-4d30-84cd-92cc7da491cf"},{"cell_type":"code","source":["# Inicializa a SparkSession (se ainda não o fez)\n","spark = SparkSession.builder.appName(\"ClientesUnicos\").getOrCreate()\n","\n","# 1. Leitura das tabelas Delta da camada bronze\n","df_clientes_consig = (\n","    spark.read.format(\"delta\")\n","    .load(\"Tables/b_vendas_clientes_consigcar\")\n","    .selectExpr(\"Nome as nome_cliente\", \"WhatsApp as whatsapp\")\n","    .distinct()\n",")\n","df_clientes_consig = df_clientes_consig.withColumn(\"empresa\", lit(\"Consigcar\"))\n","\n","df_clientes_alu = (\n","    spark.read.format(\"delta\")\n","    .load(\"Tables/b_vendas_clientes_alucar\")\n","    .selectExpr(\"`Nome__Alucar_` as nome_cliente\")\n","    .distinct()\n",")\n","df_clientes_alu = (\n","    df_clientes_alu.withColumn(\"whatsapp\", lit(None).cast(\"string\"))\n","    .withColumn(\"empresa\", lit(\"Alucar\"))\n",")\n","\n","# 2. Combina as duas tabelas\n","df_clientes = df_clientes_consig.unionByName(df_clientes_alu)\n","\n","\n","# 3. Remover valores duplicados e adicionar 'id_cliente' na primeira posição\n","\n","# Remove duplicatas primeiro\n","df_clientes_unicos = df_clientes.dropDuplicates([\"nome_cliente\"])\n","\n","# Adiciona a coluna 'id_cliente'\n","window_spec = Window.orderBy(\"nome_cliente\")\n","df_clientes_com_id = df_clientes_unicos.withColumn(\"id_cliente\", row_number().over(window_spec) - 1)\n","\n","# Pega todas as colunas existentes, exceto 'id_cliente' (se por algum motivo já existisse antes)\n","# Isso garante que não teremos duas colunas 'id_cliente' ao fazer o select final.\n","colunas_existentes = [col for col in df_clientes_com_id.columns if col != \"id_cliente\"]\n","\n","# Cria a lista final de colunas com 'id_cliente' na primeira posição\n","colunas_finais = [\"id_cliente\"] + colunas_existentes\n","\n","# Seleciona as colunas na ordem desejada\n","df_clientes_final = df_clientes_com_id.select(*colunas_finais).sort(\"id_cliente\")\n","\n","# 4. Salva a tabela na camada silver como Delta\n","df_clientes_final.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/s_dim_cliente\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"35b8594a-2d83-472e-8c92-36b1ea22ab25","normalized_state":"finished","queued_time":"2025-06-22T16:49:32.5841122Z","session_start_time":null,"execution_start_time":"2025-06-22T16:49:32.5853013Z","execution_finish_time":"2025-06-22T16:49:48.7763826Z","parent_msg_id":"8d48992b-f6d6-4267-8814-8ae3b090709c"},"text/plain":"StatementMeta(, 35b8594a-2d83-472e-8c92-36b1ea22ab25, 7, Finished, Available, Finished)"},"metadata":{}}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"624344fc-67a3-480d-8c71-5d9c591a5591"},{"cell_type":"code","source":["# Leitura da tabela Delta na camada bronze\n","df_vend = (\n","    spark.read.format(\"delta\")\n","    .load(\"Tables/b_vendas_clientes_consigcar\")\n","    .select(\"Vendedor\")\n","    .distinct()\n","    .withColumnRenamed(\"Vendedor\", \"nome_vendedor\")\n",")\n","\n","# Adiciona id_cliente único\n","df_vend = df_vend.withColumn(\"id_vendedor\", monotonically_increasing_id())\n","\n","colunas_existentes = [col for col in df_vend.columns if col != \"id_vendedor\"]\n","\n","# Cria a lista final de colunas com 'id_cliente' na primeira posição\n","colunas_finais = [\"id_vendedor\"] + colunas_existentes\n","\n","# Seleciona as colunas na ordem desejada\n","df_vendedor_final = df_vend.select(*colunas_finais).sort(\"id_vendedor\")\n","\n","# Salvar na camada silver como tabela Delta (substitui se já existir)\n","df_vendedor_final.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/s_dim_vendedor\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[8],"state":"finished","livy_statement_state":"available","session_id":"35b8594a-2d83-472e-8c92-36b1ea22ab25","normalized_state":"finished","queued_time":"2025-06-22T16:49:52.831903Z","session_start_time":null,"execution_start_time":"2025-06-22T16:49:52.8331061Z","execution_finish_time":"2025-06-22T16:49:57.5521613Z","parent_msg_id":"d5646406-e6e0-440a-8056-6ac48d6a41d4"},"text/plain":"StatementMeta(, 35b8594a-2d83-472e-8c92-36b1ea22ab25, 8, Finished, Available, Finished)"},"metadata":{}}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ea42b32d-2975-463f-9f5e-b2a49ca2c783"},{"cell_type":"code","source":["# Criar sessão Spark\n","spark = SparkSession.builder.getOrCreate()\n","\n","# Gerar intervalo de datas de 2018-01-01 a 2030-12-31\n","start_date = datetime(2018, 1, 1)\n","end_date = datetime(2030, 12, 31)\n","\n","date_list = []\n","current_date = start_date\n","while current_date <= end_date:\n","    date_list.append((int(current_date.strftime('%Y%m%d')), current_date))\n","    current_date += timedelta(days=1)\n","\n","# Criar DataFrame Spark\n","df_tempo = spark.createDataFrame(date_list, [\"id_data\", \"data\"])\n","\n","# Adicionar colunas\n","df_tempo = df_tempo.withColumn(\"dia\", dayofmonth(\"data\")) \\\n","                   .withColumn(\"mes\", month(\"data\")) \\\n","                   .withColumn(\"ano\", year(\"data\")) \\\n","                   .withColumn(\"nome_mes\", date_format(\"data\", \"MMMM\")) \\\n","                   .withColumn(\"dia_da_semana\", date_format(\"data\", \"EEEE\")) \\\n","                   .withColumn(\"trimestre\", quarter(\"data\"))\n","\n","# (Opcional) Forçar locale pt_BR se Spark estiver configurado\n","# Isso depende do locale configurado no ambiente do cluster.\n","# Ex: spark.conf.set(\"spark.sql.session.timeZone\", \"America/Sao_Paulo\")\n","\n","# Salvar como tabela Delta (Silver Layer)\n","df_tempo.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"s_dim_tempo\")\n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","session_id":"35b8594a-2d83-472e-8c92-36b1ea22ab25","normalized_state":"finished","queued_time":"2025-06-22T16:50:00.4696438Z","session_start_time":null,"execution_start_time":"2025-06-22T16:50:00.4708751Z","execution_finish_time":"2025-06-22T16:50:20.8400568Z","parent_msg_id":"0989b160-f05c-45a3-9dc5-bddc69ea09ad"},"text/plain":"StatementMeta(, 35b8594a-2d83-472e-8c92-36b1ea22ab25, 9, Finished, Available, Finished)"},"metadata":{}}],"execution_count":7,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"60786cfe-a2be-4324-9e48-3215ca65e1ab"},{"cell_type":"code","source":["\n","\n","# 1) Ler as duas tabelas Delta\n","df_alucar = spark.read.format(\"delta\").load(\"Tables/b_despesas_alucar\") \\\n","    .select(col(\"DESPESAS\").alias(\"nome_despesa\"), col(\"Valor\").alias(\"valor\"), col(\"Mês\").alias(\"mes\")) \\\n","    .withColumn(\"origem\", lit(\"Alucar\"))\n","\n","df_consig = spark.read.format(\"delta\").load(\"Tables/b_despesas_consigcar\") \\\n","    .select(col(\"DESPESAS\").alias(\"nome_despesa\"), col(\"Valor\").alias(\"valor\"), col(\"Mês\").alias(\"mes\")) \\\n","    .withColumn(\"origem\", lit(\"Consigcar\"))\n","\n","# 2) Concatenar\n","df_desp = df_alucar.unionByName(df_consig)\n","\n","# 3) Limpar coluna valor: remove 'R$', pontos, troca vírgula por ponto, trim, converte para float\n","df_desp = df_desp.withColumn(\n","    \"valor\",\n","    regexp_replace(regexp_replace(regexp_replace(trim(col(\"valor\")), \"R\\\\$\", \"\"), \"\\\\.\", \"\"), \",\", \".\").cast(FloatType())\n",")\n","\n","# 4) Criar função para mapear mês em português para número\n","meses = {\n","    'janeiro': '01', 'fevereiro': '02', 'março': '03', 'abril': '04',\n","    'maio': '05', 'junho': '06', 'julho': '07', 'agosto': '08',\n","    'setembro': '09', 'outubro': '10', 'novembro': '11', 'dezembro': '12'\n","}\n","\n","def converte_mes_udf(mes):\n","    if mes is None:\n","        return None\n","    mes = mes.lower().strip()\n","    for nome, numero in meses.items():\n","        if mes.startswith(nome):\n","            return f\"2025-{numero}-01\"\n","    return None\n","\n","udf_converte_mes = udf(converte_mes_udf, StringType())\n","\n","df_desp = df_desp.withColumn(\"data\", udf_converte_mes(col(\"mes\")))\n","\n","# 5) Converter para data e depois gerar id_data YYYYMMDD (inteiro)\n","df_desp = df_desp.withColumn(\"data_dt\", to_date(col(\"data\"), \"yyyy-MM-dd\"))\n","df_desp = df_desp.withColumn(\"id_data\", date_format(col(\"data_dt\"), \"yyyyMMdd\").cast(IntegerType()))\n","\n","# 6) Criar coluna categoria - você precisa definir a função classificar_despesa para PySpark\n","# Se for simples, pode fazer um UDF, exemplo abaixo com placeholder\n","\n","udf_classificar = udf(classificar_despesa, StringType())\n","\n","df_desp = df_desp.withColumn(\"categoria\", udf_classificar(col(\"nome_despesa\")))\n","\n","window_spec = Window.orderBy(\"nome_despesa\")\n","df_despesa_com_id = df_desp.withColumn(\"id_despesa\", row_number().over(window_spec) - 1)\n","\n","colunas_existentes = [col for col in df_despesa_com_id.columns if col != \"id_despesa\"]\n","\n","# Cria a lista final de colunas com 'id_cliente' na primeira posição\n","colunas_finais = [\"id_despesa\"] + colunas_existentes\n","\n","# Seleciona as colunas na ordem desejada\n","df_despesa_final = df_despesa_com_id.select(*colunas_finais).sort(\"id_despesa\")\n","\n","# 7) Selecionar colunas para salvar\n","df_final = df_despesa_final.select(\"id_despesa\", \"origem\", \"categoria\", \"nome_despesa\", \"valor\", \"id_data\")\n","\n","# 8) Salvar na camada silver como Delta\n","df_final.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/s_fato_despesas\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":12,"statement_ids":[12],"state":"finished","livy_statement_state":"available","session_id":"35b8594a-2d83-472e-8c92-36b1ea22ab25","normalized_state":"finished","queued_time":"2025-06-22T16:51:57.9428074Z","session_start_time":null,"execution_start_time":"2025-06-22T16:51:57.944068Z","execution_finish_time":"2025-06-22T16:52:22.7130055Z","parent_msg_id":"85117ff5-9421-4aee-9279-99eae34d1422"},"text/plain":"StatementMeta(, 35b8594a-2d83-472e-8c92-36b1ea22ab25, 12, Finished, Available, Finished)"},"metadata":{}}],"execution_count":10,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9f830c12-0efd-4b6b-9837-d19ecefc0535"},{"cell_type":"code","source":["# 1) Ler a tabela Delta\n","df_pag = spark.read.format(\"delta\").load(\"Tables/b_receita_pagseguro_consigcar\") \\\n","    .select(col(\"Data\").alias(\"data\"), col(\"Valor\").alias(\"valor_faturado\"))\n","\n","# 2) Converter data para id_data no formato YYYYMMDD inteiro\n","df_pag = df_pag.withColumn(\"data_dt\", to_date(col(\"data\"), \"yyyy-MM-dd\"))  # Ajuste o formato se necessário\n","df_pag = df_pag.withColumn(\"id_data\", date_format(col(\"data_dt\"), \"yyyyMMdd\").cast(IntegerType()))\n","\n","# 3) Limpar e converter valor_faturado para float\n","df_pag = df_pag.withColumn(\n","    \"valor_faturado\",\n","    regexp_replace(regexp_replace(regexp_replace(trim(col(\"valor_faturado\")), \"R\\\\$\", \"\"), \"\\\\.\", \"\"), \",\", \".\").cast(FloatType())\n",")\n","\n","window_spec = Window.orderBy(\"id_data\")\n","df_pag = df_pag.withColumn(\"id_faturamento\", row_number().over(window_spec) - 1)\n","\n","colunas_existentes = [col for col in df_pag.columns if col != \"id_faturamento\"]\n","\n","# Cria a lista final de colunas com 'id_cliente' na primeira posição\n","colunas_finais = [\"id_faturamento\"] + colunas_existentes\n","\n","# Seleciona as colunas na ordem desejada\n","df_pag_final = df_pag.select(*colunas_finais).sort(\"id_faturamento\")\n","\n","# 4) Selecionar colunas para salvar\n","df_final = df_pag_final.select(\"id_faturamento\",\"id_data\", \"valor_faturado\")\n","\n","\n","# Corrigir os id_data que não terminam com '01'\n","df_final = df_final.withColumn(\n","    \"id_data\",\n","    when(col(\"id_data\") % 100 != 1,  # verifica se os dois últimos dígitos são diferentes de 01\n","         expr(\"cast(int(id_data / 100) * 100 + 1 as int)\")  # troca os dois últimos dígitos por 01\n","    ).otherwise(col(\"id_data\"))  # mantém se já termina com 01\n",")\n","\n","# 5) Salvar na camada silver (Delta)\n","df_final.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/s_fato_faturamento_pagseguro\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":13,"statement_ids":[13],"state":"finished","livy_statement_state":"available","session_id":"35b8594a-2d83-472e-8c92-36b1ea22ab25","normalized_state":"finished","queued_time":"2025-06-22T16:52:26.4921857Z","session_start_time":null,"execution_start_time":"2025-06-22T16:52:26.4934157Z","execution_finish_time":"2025-06-22T16:52:31.2788074Z","parent_msg_id":"a125ae73-8c17-46bd-b0a8-b12a35550e28"},"text/plain":"StatementMeta(, 35b8594a-2d83-472e-8c92-36b1ea22ab25, 13, Finished, Available, Finished)"},"metadata":{}}],"execution_count":11,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7e9a108b-fd65-44ad-b972-84ba1d76157a"},{"cell_type":"code","source":["# Definindo a janela ordenada para o row_number\n","window_spec = Window.orderBy(\"Data\", \"Nome__Alucar_\")\n","\n","# 1. Ler a tabela Delta com os dados da Alucar\n","df_val = (\n","    spark.read.format(\"delta\")\n","    .load(\"Tables/b_vendas_clientes_alucar\")\n","    .select(\"Data\", \"Valor_Receita\", \"Nome__Alucar_\")\n","    .withColumn(\"id_venda_alucar\", row_number().over(window_spec))\n","    .withColumnRenamed(\"Data\", \"data\")\n","    .withColumnRenamed(\"Valor_Receita\", \"valor_venda\")\n","    .withColumnRenamed(\"Nome__Alucar_\", \"nome_cliente\")\n",")\n","\n","# 2. Ler a dimensão cliente\n","df_clientes = (\n","    spark.read.format(\"delta\")\n","    .load(\"Tables/s_dim_cliente\")\n","    .select(\"id_cliente\", \"nome_cliente\")\n",")\n","\n","# 3. Juntar com dim_cliente\n","df_val = df_val.join(df_clientes, on=\"nome_cliente\", how=\"left\")\n","\n","# 4. Criar id_data no formato YYYYMMDD\n","df_val = df_val.withColumn(\"data_formatada\", to_date(\"data\", \"yyyy-MM-dd\"))\n","df_val = df_val.withColumn(\"id_data\", date_format(\"data_formatada\", \"yyyyMMdd\").cast(IntegerType()))\n","\n","# 5. Converter valor_venda de R$ X.XXX,XX para float\n","df_val = (\n","    df_val.withColumn(\"valor_venda\", regexp_replace(\"valor_venda\", \"R\\\\$\", \"\"))\n","           .withColumn(\"valor_venda\", regexp_replace(\"valor_venda\", \"\\\\.\", \"\"))\n","           .withColumn(\"valor_venda\", regexp_replace(\"valor_venda\", \",\", \".\"))\n","           .withColumn(\"valor_venda\", col(\"valor_venda\").cast(\"float\"))\n",")\n","\n","# 6. Selecionar colunas finais\n","df_val_final = df_val.select(\"id_venda_alucar\", \"id_cliente\", \"id_data\", \"valor_venda\")\n","\n","# 7. Salvar como Delta\n","df_val_final.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/s_fato_vendas_alucar\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":14,"statement_ids":[14],"state":"finished","livy_statement_state":"available","session_id":"35b8594a-2d83-472e-8c92-36b1ea22ab25","normalized_state":"finished","queued_time":"2025-06-22T16:52:34.0519192Z","session_start_time":null,"execution_start_time":"2025-06-22T16:52:34.0530053Z","execution_finish_time":"2025-06-22T16:52:40.2233764Z","parent_msg_id":"c0306bb0-6dbe-4770-a4a1-71f79b564543"},"text/plain":"StatementMeta(, 35b8594a-2d83-472e-8c92-36b1ea22ab25, 14, Finished, Available, Finished)"},"metadata":{}}],"execution_count":12,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4a4be04e-a97e-4511-a1b0-484fef0ff78a"},{"cell_type":"code","source":["# 1) Leitura da tabela 00_vendas_clientes_consigcar da camada bronze\n","df_cons = (\n","    spark.read.format(\"delta\")\n","    .load(\"Tables/b_vendas_clientes_consigcar\")\n","    .selectExpr(\n","        \"row_number() OVER (ORDER BY Nome) as id_venda_consigcar\",  # cria id sequencial (se não existir id)\n","        \"Nome as nome_cliente\",\n","        \"`Tipo_Produto` as tipo_produto\",\n","        \"`Quantidade_de_vezes` as num_parcelas\",\n","        \"`Valor_parcela` as valor_parcela\",\n","        \"Vendedor as nome_vendedor\",\n","        \"`Data_do_pagamento` as data_primeira_parcela\"\n","    )\n",")\n","\n","# Se a tabela já tem uma chave única (ex: rowid), use ela para id_venda_consigcar no lugar do row_number\n","\n","# 2) Calcular valor_total = num_parcelas * valor_parcela\n","df_cons = df_cons.withColumn(\"valor_total\", col(\"num_parcelas\") * col(\"valor_parcela\"))\n","\n","# 3) Converter data_primeira_parcela para date\n","df_cons = df_cons.withColumn(\"data_primeira_parcela\", to_date(\"data_primeira_parcela\", \"yyyy-MM-dd\"))\n","\n","# 4) Calcular data_ultima_parcela = data_primeira_parcela + (num_parcelas - 1) meses\n","# Spark não tem diretamente add months com col * int, então usamos expr com INTERVAL e SQL\n","df_cons = df_cons.withColumn(\n","    \"data_ultima_parcela\",\n","    expr(\"add_months(data_primeira_parcela, CAST(num_parcelas AS int) - 1)\")\n",")\n","\n","# 5) Formatar as datas no formato YYYYMMDD como int\n","df_cons = df_cons.withColumn(\n","    \"data_primeira_parcela\", date_format(\"data_primeira_parcela\", \"yyyyMMdd\").cast(IntegerType())\n",").withColumn(\n","    \"data_ultima_parcela\", date_format(\"data_ultima_parcela\", \"yyyyMMdd\").cast(IntegerType())\n",")\n","\n","# 6) Ler dim_cliente para obter id_cliente\n","df_clientes = spark.read.format(\"delta\").load(\"Tables/s_dim_cliente\").select(\"id_cliente\", \"nome_cliente\")\n","\n","# 7) Ler dim_vendedor para obter id_vendedor\n","df_vend = spark.read.format(\"delta\").load(\"Tables/s_dim_vendedor\").select(\"id_vendedor\", \"nome_vendedor\")\n","\n","# 8) Fazer join para incluir id_cliente e id_vendedor\n","df_cons = df_cons.join(df_clientes, on=\"nome_cliente\", how=\"left\")\n","df_cons = df_cons.join(df_vend, on=\"nome_vendedor\", how=\"left\")\n","\n","# 9) Selecionar colunas relevantes\n","colunas_fato = [\n","    \"id_venda_consigcar\", \"id_cliente\", \"tipo_produto\", \"id_vendedor\",\n","    \"num_parcelas\", \"valor_parcela\", \"valor_total\",\n","    \"data_primeira_parcela\", \"data_ultima_parcela\"\n","]\n","df_fato = df_cons.select(colunas_fato)\n","\n","# 10) Salvar tabela fato na camada silver\n","df_fato.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/s_fato_vendas_consigcar\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":15,"statement_ids":[15],"state":"finished","livy_statement_state":"available","session_id":"35b8594a-2d83-472e-8c92-36b1ea22ab25","normalized_state":"finished","queued_time":"2025-06-22T16:52:43.2809577Z","session_start_time":null,"execution_start_time":"2025-06-22T16:52:43.2822054Z","execution_finish_time":"2025-06-22T16:52:48.0891731Z","parent_msg_id":"dc8e781f-928a-4041-a0a6-d770d9348251"},"text/plain":"StatementMeta(, 35b8594a-2d83-472e-8c92-36b1ea22ab25, 15, Finished, Available, Finished)"},"metadata":{}}],"execution_count":13,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"99f1f5db-db57-4893-8b33-c5808a4c4b89"},{"cell_type":"code","source":["# 1) Ler fato_vendas_consigcar da camada silver\n","df_vendas = spark.read.format(\"delta\").load(\"Tables/s_fato_vendas_consigcar\")\n","\n","# 2) Ler dim_tempo da camada silver\n","df_tempo = spark.read.format(\"delta\").load(\"Tables/s_dim_tempo\")\n","\n","# 3) Fazer join entre fato_vendas_consigcar e dim_tempo\n","# Aqui usamos cast para comparar os IDs corretamente\n","df_joined = df_vendas.join(\n","    df_tempo,\n","    df_vendas[\"data_primeira_parcela\"].cast(\"string\") == df_tempo[\"id_data\"],\n","    how=\"inner\"\n",")\n","\n","# 4) Agregar: total de vendas e soma de valor_total por id_vendedor e id_data\n","df_vendas_diaria = (\n","    df_joined.groupBy(\"id_vendedor\", \"id_data\",\"valor_parcela\")\n","    .agg(\n","        count(\"*\").alias(\"total_vendas\"),\n","        spark_sum(\"valor_total\").alias(\"valor_total\")\n","    )\n",")\n","\n","# 5) Salvar a tabela na camada silver\n","df_vendas_diaria.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/s_fato_vendas_diaria_vendedor\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":16,"statement_ids":[16],"state":"finished","livy_statement_state":"available","session_id":"35b8594a-2d83-472e-8c92-36b1ea22ab25","normalized_state":"finished","queued_time":"2025-06-22T16:52:51.938608Z","session_start_time":null,"execution_start_time":"2025-06-22T16:52:51.9398536Z","execution_finish_time":"2025-06-22T16:52:58.3047321Z","parent_msg_id":"024261e9-d7f0-4aab-bf9b-06d7ca1a691c"},"text/plain":"StatementMeta(, 35b8594a-2d83-472e-8c92-36b1ea22ab25, 16, Finished, Available, Finished)"},"metadata":{}}],"execution_count":14,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f56cb789-b0f0-429b-9bdb-6053f61387a4"},{"cell_type":"code","source":["# 1. Carregar os dados da fato_vendas_consigcar\n","df_vendas = spark.read.format(\"delta\").load(\"Tables/s_fato_vendas_consigcar\")\n","\n","# 2. Converter data_primeira_parcela (formato Int YYYYMMDD) para data real\n","df_vendas = df_vendas.withColumn(\n","    \"data_inicial\",\n","    to_date(col(\"data_primeira_parcela\").cast(\"string\"), \"yyyyMMdd\")\n",")\n","\n","# 3. Criar a sequência de datas mensais para cada parcela\n","df_vendas = df_vendas.withColumn(\n","    \"datas_pagamento\",\n","    sequence(\n","        col(\"data_inicial\"),\n","        expr(\"add_months(data_inicial, num_parcelas - 1)\"),\n","        expr(\"interval 1 month\")\n","    )\n",")\n","\n","# 4. Explodir as datas e formatar como id_data (YYYYMMDD)\n","df_pagamentos = df_vendas.select(\n","    col(\"id_venda_consigcar\"),\n","    col(\"valor_parcela\").alias(\"valor\"),\n","    explode(\"datas_pagamento\").alias(\"data_pagamento\")\n",").withColumn(\n","    \"id_data\", date_format(col(\"data_pagamento\"), \"yyyyMMdd\").cast(IntegerType())\n",").select(\"id_venda_consigcar\", \"valor\", \"id_data\")\n","\n","# 5. Salvar como tabela Delta na camada silver\n","df_pagamentos.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/s_dim_pagamentos_programados\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":17,"statement_ids":[17],"state":"finished","livy_statement_state":"available","session_id":"35b8594a-2d83-472e-8c92-36b1ea22ab25","normalized_state":"finished","queued_time":"2025-06-22T16:52:59.6932003Z","session_start_time":null,"execution_start_time":"2025-06-22T16:52:59.6944019Z","execution_finish_time":"2025-06-22T16:53:03.1506927Z","parent_msg_id":"880c93f4-aaba-49d9-aa89-db5b01b7db48"},"text/plain":"StatementMeta(, 35b8594a-2d83-472e-8c92-36b1ea22ab25, 17, Finished, Available, Finished)"},"metadata":{}}],"execution_count":15,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"01662c86-ede3-445a-b0bb-e23f2c29e4da"},{"cell_type":"code","source":["# Inicializa a SparkSession (se ainda não o fez)\n","spark = SparkSession.builder.appName(\"MetasAlucar\").getOrCreate()\n","\n","# 1. Carregar os dados da tabela \"00_metas_plr\"\n","df_metas = spark.read.format(\"delta\").load(\"Tables/b_metas_plr\")\n","\n","# 2. Converter a coluna Data para id_data (formato Int: YYYYMMDD)\n","df_metas = df_metas.withColumn(\"id_data\", date_format(to_date(col(\"Data\")), \"yyyyMMdd\").cast(\"int\"))\n","\n","# 3. Selecionar e renomear colunas\n","df_metas = df_metas.select(\n","    \"id_data\",\n","    col(\"Meta_1_ALUCAR\").alias(\"meta_vendas_1_cum\"),\n","    col(\"Meta_2_ALUCAR\").alias(\"meta_vendas_2_cum\")\n",")\n","\n","\n","# 4. Calcular metas mensais com .diff() via função lag\n","#    Definindo default=0 para 'lag()' para que a primeira linha de 'meta_vendas_X_mes'\n","#    seja igual ao 'meta_vendas_X_cum' correspondente.\n","window_spec = Window.orderBy(\"id_data\")\n","\n","df_metas = df_metas.withColumn(\n","    \"meta_vendas_1_mes\",\n","    col(\"meta_vendas_1_cum\") - lag(\"meta_vendas_1_cum\", 1, 0).over(window_spec) # <-- Default agora é 0\n",").withColumn(\n","    \"meta_vendas_2_mes\",\n","    col(\"meta_vendas_2_cum\") - lag(\"meta_vendas_2_cum\", 1, 0).over(window_spec) # <-- Default agora é 0\n",")\n","\n","# ---\n","\n","# 5. Para o primeiro mês do ano (janeiro), usar o valor cumulativo diretamente\n","#    Esta lógica ainda é útil se suas metas cumulativas resetam anualmente.\n","df_metas = df_metas.withColumn(\n","    \"mes\",\n","    date_format(col(\"id_data\").cast(\"string\"), \"MMdd\").substr(1, 2)\n",")\n","\n","df_metas = df_metas.withColumn(\n","    \"meta_vendas_1_mes\",\n","    when(col(\"mes\") == \"01\", col(\"meta_vendas_1_cum\")).otherwise(col(\"meta_vendas_1_mes\"))\n",").withColumn(\n","    \"meta_vendas_2_mes\",\n","    when(col(\"mes\") == \"01\", col(\"meta_vendas_2_cum\")).otherwise(col(\"meta_vendas_2_mes\"))\n",").drop(\"mes\")\n","\n","# ---\n","\n","# 6. Salvar a tabela como Delta na camada Silver\n","df_metas.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/s_fato_metas_alucar\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":18,"statement_ids":[18],"state":"finished","livy_statement_state":"available","session_id":"35b8594a-2d83-472e-8c92-36b1ea22ab25","normalized_state":"finished","queued_time":"2025-06-22T16:53:05.1360926Z","session_start_time":null,"execution_start_time":"2025-06-22T16:53:05.1373267Z","execution_finish_time":"2025-06-22T16:53:09.8691556Z","parent_msg_id":"c26728bb-fac1-4674-96f1-2525044d1fb2"},"text/plain":"StatementMeta(, 35b8594a-2d83-472e-8c92-36b1ea22ab25, 18, Finished, Available, Finished)"},"metadata":{}}],"execution_count":16,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"78af5ac5-04d8-4ccc-a5f3-069b22804ef6"},{"cell_type":"code","source":["# Initialize SparkSession if not already done\n","spark = SparkSession.builder.appName(\"MetasConsigcar\").getOrCreate()\n","\n","# 1. Load data from the \"00_metas_plr\" table\n","df_metas_consig = spark.read.format(\"delta\").load(\"Tables/b_metas_plr\")\n","\n","# 2. Convert the 'Data' column to 'id_data' (YYYYMMDD int)\n","df_metas_consig = df_metas_consig.withColumn(\n","    \"id_data\",\n","    date_format(col(\"Data\"), \"yyyyMMdd\").cast(\"int\")\n",")\n","\n","# 3. Select and rename columns\n","df_metas_consig = df_metas_consig.select(\n","    \"id_data\",\n","    col(\"Meta_1_ConsigCar\").alias(\"meta_vendas_1_cum\"),\n","    col(\"Meta_2_ConsigCar\").alias(\"meta_vendas_2_cum\")\n",")\n","\n","\n","# 4. Calculate monthly targets using lag (difference)\n","#    Setting default=0 for lag ensures that the first row's 'mes' value\n","#    is equal to its 'cum' value (cum - 0 = cum).\n","window_spec = Window.orderBy(\"id_data\")\n","\n","df_metas_consig = df_metas_consig.withColumn(\n","    \"meta_vendas_1_mes\",\n","    col(\"meta_vendas_1_cum\") - lag(\"meta_vendas_1_cum\", 1, 0).over(window_spec) # <-- Default agora é 0\n",").withColumn(\n","    \"meta_vendas_2_mes\",\n","    col(\"meta_vendas_2_cum\") - lag(\"meta_vendas_2_cum\", 1, 0).over(window_spec) # <-- Default agora é 0\n",")\n","\n","# ---\n","\n","# 5. Adjust for the first month of EACH YEAR (January)\n","#    This logic will override the above calculation if it's January and\n","#    you want the monthly value to be the cumulative for that start of year.\n","df_metas_consig = df_metas_consig.withColumn(\n","    \"mes\",\n","    date_format(col(\"id_data\").cast(\"string\"), \"MMdd\").substr(1, 2)\n",")\n","\n","df_metas_consig = df_metas_consig.withColumn(\n","    \"meta_vendas_1_mes\",\n","    when(col(\"mes\") == \"01\", col(\"meta_vendas_1_cum\")).otherwise(col(\"meta_vendas_1_mes\"))\n",").withColumn(\n","    \"meta_vendas_2_mes\",\n","    when(col(\"mes\") == \"01\", col(\"meta_vendas_2_cum\")).otherwise(col(\"meta_vendas_2_mes\"))\n",").drop(\"mes\")\n","\n","# ---\n","\n","# 6. Save the resulting table to the Silver layer (Delta format)\n","df_metas_consig.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/s_fato_metas_consigcar\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":19,"statement_ids":[19],"state":"finished","livy_statement_state":"available","session_id":"35b8594a-2d83-472e-8c92-36b1ea22ab25","normalized_state":"finished","queued_time":"2025-06-22T16:53:19.3836914Z","session_start_time":null,"execution_start_time":"2025-06-22T16:53:19.3849324Z","execution_finish_time":"2025-06-22T16:53:22.8114368Z","parent_msg_id":"e2b6208d-ea4b-466c-8309-7c9248ff58c2"},"text/plain":"StatementMeta(, 35b8594a-2d83-472e-8c92-36b1ea22ab25, 19, Finished, Available, Finished)"},"metadata":{}}],"execution_count":17,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"51b1dd5e-80f9-41b2-9edb-ccc144281ace"},{"cell_type":"code","source":["# 1. Carregar os dados da tabela \"00_vendas_clientes_alucar_estimativa\"\n","df_vendas_estimativa = spark.read.format(\"delta\").load(\"Tables/b_vendas_clientes_alucar_estimativa\")\n","\n","# 2. Converter a coluna Data para id_data (YYYYMMDD int)\n","df_vendas_estimativa = df_vendas_estimativa.withColumn(\n","    \"id_data\",\n","    date_format(col(\"Data\"), \"yyyyMMdd\").cast(\"int\")\n",")\n","\n","# 3. Selecionar e renomear colunas\n","df_vendas_estimativa = df_vendas_estimativa.select(\n","    \"id_data\",\n","    col(\"Nome__Alucar_\").alias(\"nome\"),\n","    col(\"Valor_Receita\").alias(\"valor_receita_estimativa\")\n",")\n","\n","# 4. Remover 'R$', pontos e substituir vírgula por ponto para conversão numérica\n","df_vendas_estimativa = df_vendas_estimativa.withColumn(\n","    \"valor_receita_estimativa\",\n","    regexp_replace(col(\"valor_receita_estimativa\"), \"R\\\\$\", \"\")  # Remove 'R$'\n",")\n","\n","df_vendas_estimativa = df_vendas_estimativa.withColumn(\n","    \"valor_receita_estimativa\",\n","    regexp_replace(col(\"valor_receita_estimativa\"), \"\\\\.\", \"\")  # Remove pontos de milhar\n",")\n","\n","df_vendas_estimativa = df_vendas_estimativa.withColumn(\n","    \"valor_receita_estimativa\",\n","    regexp_replace(col(\"valor_receita_estimativa\"), \",\", \".\")  # Troca vírgula por ponto decimal\n",")\n","\n","# 5. Converter para float\n","df_vendas_estimativa = df_vendas_estimativa.withColumn(\n","    \"valor_receita_estimativa\",\n","    col(\"valor_receita_estimativa\").cast(\"float\")\n",")\n","\n","# 6. Salvar a tabela no formato Delta ou conforme sua arquitetura\n","df_vendas_estimativa.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/s_fato_vendas_clientes_alucar_estimativa\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":20,"statement_ids":[20],"state":"finished","livy_statement_state":"available","session_id":"35b8594a-2d83-472e-8c92-36b1ea22ab25","normalized_state":"finished","queued_time":"2025-06-22T16:53:26.1138486Z","session_start_time":null,"execution_start_time":"2025-06-22T16:53:26.1151146Z","execution_finish_time":"2025-06-22T16:53:30.8429724Z","parent_msg_id":"cb0854e5-3ce4-45a7-8df7-704cc760a9d1"},"text/plain":"StatementMeta(, 35b8594a-2d83-472e-8c92-36b1ea22ab25, 20, Finished, Available, Finished)"},"metadata":{}}],"execution_count":18,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"169b61bd-95be-4121-b9bf-105fd475ecf7"},{"cell_type":"code","source":["# 1. Carregar os dados da tabela \"00_receita_consigcar_estimativa\"\n","df_consig_estimativa = spark.read.format(\"delta\").load(\"Tables/b_receita_consigcar_estimativa\")\n","\n","# 2. Converter a coluna Data para id_data no formato YYYYMMDD (inteiro)\n","df_consig_estimativa = df_consig_estimativa.withColumn(\n","    \"id_data\",\n","    date_format(col(\"Data\"), \"yyyyMMdd\").cast(\"int\")\n",")\n","\n","# 3. Selecionar e renomear colunas\n","df_consig_estimativa = df_consig_estimativa.select(\n","    \"id_data\",\n","    col(\"Valor\").alias(\"valor_receita_estimativa\")\n",")\n","\n","# 4. Remover 'R$', pontos e substituir vírgula por ponto para conversão numérica\n","df_consig_estimativa = df_consig_estimativa.withColumn(\n","    \"valor_receita_estimativa\",\n","    regexp_replace(col(\"valor_receita_estimativa\"), \"R\\\\$\", \"\")\n",")\n","\n","df_consig_estimativa = df_consig_estimativa.withColumn(\n","    \"valor_receita_estimativa\",\n","    regexp_replace(col(\"valor_receita_estimativa\"), \"\\\\.\", \"\")\n",")\n","\n","df_consig_estimativa = df_consig_estimativa.withColumn(\n","    \"valor_receita_estimativa\",\n","    regexp_replace(col(\"valor_receita_estimativa\"), \",\", \".\")\n",")\n","\n","# 5. Converter para float\n","df_consig_estimativa = df_consig_estimativa.withColumn(\n","    \"valor_receita_estimativa\",\n","    col(\"valor_receita_estimativa\").cast(\"float\")\n",")\n","\n","# 6. Salvar a tabela no formato Delta ou conforme sua arquitetura\n","df_consig_estimativa.write.format(\"delta\").mode(\"overwrite\").save(\"Tables/s_fato_consigcar_estimativa\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":21,"statement_ids":[21],"state":"finished","livy_statement_state":"available","session_id":"35b8594a-2d83-472e-8c92-36b1ea22ab25","normalized_state":"finished","queued_time":"2025-06-22T16:53:34.0825972Z","session_start_time":null,"execution_start_time":"2025-06-22T16:53:34.083937Z","execution_finish_time":"2025-06-22T16:53:38.8278109Z","parent_msg_id":"4b3ba483-9b31-4672-a1ae-0a3165e7be42"},"text/plain":"StatementMeta(, 35b8594a-2d83-472e-8c92-36b1ea22ab25, 21, Finished, Available, Finished)"},"metadata":{}}],"execution_count":19,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c152e2be-1926-40dc-88a5-c7d9c1a16708"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"4a780a82-5b79-440f-b832-289c5aa59c04","known_lakehouses":[{"id":"4a780a82-5b79-440f-b832-289c5aa59c04"}],"default_lakehouse_name":"lakehouse_vendas","default_lakehouse_workspace_id":"9192c1ef-ef1d-4e27-8495-7193eb001d77"}}},"nbformat":4,"nbformat_minor":5}