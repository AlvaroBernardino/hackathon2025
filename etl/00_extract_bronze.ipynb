{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e210583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas\n",
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine, inspect, text\n",
    "from io import BytesIO\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from utils import sql_to_dbml, edit_sheet # Importando as funções do arquivo utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ce90ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionários\n",
    "# com os caminhos do arquivos e atributos da tabela\n",
    "\n",
    "base1 = {\n",
    "    \"sheet_id\": \"1cucnW4yVosO5n5BFgwXYv6rVy8yj6NTasM83RTCMOug\",\n",
    "    \"gid_receita\": \"373473243\",\n",
    "    \"gid_despesas\": \"1859279676\",\n",
    "    \"gid_PLR\": \"835809915\",\n",
    "    \"encoding\": \"latin1\",\n",
    "    \"db_path\": os.path.abspath(\"../database/bronze/00_base1.db\"),\n",
    "    \"dbml_path\": os.path.abspath(\"../modelagem/00_base1.dbml\"),\n",
    "}\n",
    "\n",
    "base2 = {\n",
    "    \"url\": \"https://empregadados-my.sharepoint.com/personal/bianca_empregadados_com_br/_layouts/15/download.aspx?share=EZYutqfo5ldNhDw2lMYRxrIBnpPI6c7OTjBBS_F5yz860Q\",\n",
    "    \"db_path\": os.path.abspath(\"../database/bronze/00_base2.db\"),\n",
    "    \"dbml_path\": os.path.abspath(\"../modelagem/00_base2.dbml\"),\n",
    "    \"encoding\": \"latin1\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd207722",
   "metadata": {},
   "source": [
    "## Extraindo Base 1 (Vendas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db74cfe7",
   "metadata": {},
   "source": [
    "### Aba Receita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73e7e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lendo e armazenando em um dataframe as tabelas\n",
    "df_Receita = pd.read_csv(f\"https://docs.google.com/spreadsheets/d/{base1['sheet_id']}/export?format=csv&gid={base1['gid_receita']}\", index_col=False)\n",
    "df_Receita = edit_sheet(df_Receita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fcca908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inciando tratamento\n",
    "# Criando dataframe Consigcar Estimativa\n",
    "df_Receita_ConsigCar_estimativa = df_Receita[df_Receita[\"Faturamento_ConsigCar\"] == \"Pagseguro\"] \\\n",
    "                                .iloc[:, [1,6]].reset_index(drop = True)\n",
    "\n",
    "for i in range(1,len(df_Receita_ConsigCar_estimativa)):\n",
    "    if pd.isna(df_Receita_ConsigCar_estimativa.loc[i,'Data']):\n",
    "        prev_date = pd.to_datetime(df_Receita_ConsigCar_estimativa.loc[i-1, 'Data'], format='%d/%m/%Y')\n",
    "        next_date = prev_date + pd.DateOffset(months=1)\n",
    "        if i == 1:  # Caso especial para a primeira data\n",
    "            df_Receita_ConsigCar_estimativa.loc[i,'Data'] = prev_date.strftime('%d/%m/%Y')\n",
    "        else:\n",
    "            df_Receita_ConsigCar_estimativa.loc[i,'Data'] = next_date.strftime('%d/%m/%Y')\n",
    "\n",
    "############# Verificar isso depois #############\n",
    "# Gambiarra para corrigir o problema com a primeira data da tabela\n",
    "# df_Receita_ConsigCar_estimativa.loc[0, 'Data'] = pd.to_datetime('2025-01-01').date()\n",
    "\n",
    "df_Receita_ConsigCar_estimativa['Data'] = pd.to_datetime(df_Receita_ConsigCar_estimativa['Data'], format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Exclusão de linhas sem dados nas colunas Data e Mês\n",
    "df_Receita = df_Receita.dropna(subset=[\"Data\", \"Mes\"])\n",
    "\n",
    "# Transformação da coluna data\n",
    "df_Receita['Data'] = pd.to_datetime(df_Receita['Data'], dayfirst = True).dt.date\n",
    "\n",
    "# Transformação das colunas Mês e Ano para inteiro\n",
    "df_Receita[\"Mes\"] = df_Receita[\"Mes\"].astype(int)\n",
    "df_Receita[\"Ano\"] = df_Receita[\"Ano\"].astype(int)\n",
    "\n",
    "# Separação das colunas da Alucar e Consigcar\n",
    "df_Receita_Alucar = df_Receita.iloc[:, 0:5] \\\n",
    "                    .reset_index(drop = True)\n",
    "\n",
    "df_Receita_ConsigCar = df_Receita.iloc[:, [1,6]] \\\n",
    "                        .dropna(subset=[\"Valor\"]) \\\n",
    "                        .reset_index(drop = True)\n",
    "\n",
    "############# Verificar isso depois #############\n",
    "# Gambiarra para corrigir o problema com a primeira data da tabela\n",
    "# df_Receita_ConsigCar.loc[0, 'Data'] = pd.to_datetime('2025-01-01').date()\n",
    "\n",
    "#     \n",
    "df_Receita_Alucar_estimativa = df_Receita_Alucar.reset_index(drop = True)\n",
    "\n",
    "df_Receita_Alucar = df_Receita_Alucar[df_Receita_Alucar[\"Nome_(Alucar)\"] != 'Estimativa']\n",
    "\n",
    "# Cria conexão com banco de dados SQLite\n",
    "engine1 = create_engine(f\"sqlite:///{base1['db_path']}\")\n",
    "\n",
    "# Insere as tabelas no banco\n",
    "df_Receita_Alucar.to_sql(\"b_vendas_clientes_alucar\", con=engine1, if_exists=\"replace\", index=False)\n",
    "df_Receita_Alucar_estimativa.to_sql(\"b_vendas_clientes_alucar_estimativa\", con=engine1, if_exists=\"replace\", index=False)\n",
    "df_Receita_ConsigCar.to_sql(\"b_receita_pagseguro_consigcar\", con=engine1, if_exists=\"replace\", index=False)\n",
    "df_Receita_ConsigCar_estimativa.to_sql(\"b_receita_consigcar_estimativa\", con=engine1, if_exists=\"replace\", index=False)\n",
    "\n",
    "# print(df_Receita_ConsigCar_estimativa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4a2fce",
   "metadata": {},
   "source": [
    "### Aba Despesas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "187a90a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lendo e armazenando em um dataframe as tabelas\n",
    "df_Despesas = pd.read_csv(f\"https://docs.google.com/spreadsheets/d/{base1[\"sheet_id\"]}/export?format=csv&gid={base1[\"gid_despesas\"]}\", index_col=False)\n",
    "\n",
    "# Excluindo colunas desnecessárias\n",
    "df_Despesas.columns = df_Despesas.iloc[0]\n",
    "df_Despesas = df_Despesas[1:]\n",
    "df_Despesas.reset_index(drop = True, inplace = True)\n",
    "\n",
    "#Separando Despesas da Alucar e ConsigCar\n",
    "\n",
    "# Encontrar o índice da linha que contém TOTAL na coluna Despesa\n",
    "index_total = df_Despesas[df_Despesas['DESPESAS'].str.contains(\"TOTAL\", na=False)].index.min()\n",
    "\n",
    "# Selecionar todas as linhas até a linha anterior à que contém TOTAL\n",
    "df_Despesas_Alucar = df_Despesas.iloc[:index_total].copy()\n",
    "df_Despesas_Alucar = df_Despesas_Alucar.reset_index(drop = True) \\\n",
    "                                       .melt(id_vars=[\"DESPESAS\"], var_name=\"Mês\", value_name=\"Valor\")\n",
    "\n",
    "# Selecionar as linhas referentes a ConsigCar\n",
    "df_Despesas_ConsigCar = df_Despesas.iloc[index_total+4:-1] \\\n",
    "                        .copy().reset_index(drop = True) \\\n",
    "                        .melt(id_vars=[\"DESPESAS\"], var_name=\"Mês\", value_name=\"Valor\")\n",
    "\n",
    "# Cria conexão com banco de dados SQLite\n",
    "engine1 = create_engine(f\"sqlite:///{base1[\"db_path\"]}\")\n",
    "\n",
    "# Insere as tabelas no banco\n",
    "df_Despesas_Alucar.to_sql(\"b_despesas_alucar\", con=engine1, if_exists=\"replace\", index=False)\n",
    "df_Despesas_ConsigCar.to_sql(\"b_despesas_consigcar\", con=engine1, if_exists=\"replace\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39925f2f",
   "metadata": {},
   "source": [
    "### Metas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "07fa7ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lendo e armazenando em um dataframe as tabelas\n",
    "df_metas = pd.read_csv(f\"https://docs.google.com/spreadsheets/d/{base1['sheet_id']}/export?format=csv&gid={base1['gid_PLR']}\", index_col=False, header=2)\n",
    "df_metas = edit_sheet(df_metas)\n",
    "# print(df_metas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e57c8737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tratamento dos dados relacionados as metas\n",
    "df_metas.columns = df_metas.columns.map(str)\n",
    "df_metas = df_metas.loc[:, ~df_metas.columns.str.contains('^Unnamed')]\n",
    "df_metas = df_metas.iloc[:-1].fillna(0)\n",
    "df_metas = edit_sheet(df_metas)\n",
    "df_metas['Mês'] = df_metas['Mês'].astype(int)\n",
    "df_metas = df_metas.rename(columns={'Meta_1': 'Meta_1_ALUCAR', 'Meta_2': 'Meta_2_ALUCAR', 'Meta_1.1': 'Meta_1_ConsigCar', 'Meta_2.1': 'Meta_2_ConsigCar'})\n",
    "df_metas = df_metas[['Ano','Mês', 'Meta_1_ALUCAR', 'Meta_2_ALUCAR', 'Meta_1_ConsigCar', 'Meta_2_ConsigCar']]\n",
    "df_metas['Ano'] = df_metas['Ano'].iloc[0]\n",
    "df_metas['Data'] = pd.to_datetime({\n",
    "    'year': df_metas['Ano'].astype(int),\n",
    "    'month': df_metas['Mês'].astype(int),\n",
    "    'day': 1\n",
    "})\n",
    "\n",
    "# Inserir PLR na base1\n",
    "df_metas.to_sql(\"b_metas_plr\", con=engine1, if_exists=\"replace\", index=False)\n",
    "\n",
    "# print(df_metas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06682d62",
   "metadata": {},
   "source": [
    "### Extraindo Base 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b78cf61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lendo e armazenando em um dataframe as tabelas\n",
    "\n",
    "response = requests.get(base2[\"url\"])\n",
    "df = pd.read_excel(BytesIO(response.content))\n",
    "\n",
    "# Remove 'R$', pontos e converte a vírgula decimal para ponto\n",
    "df['Valor parcela'] = df['Valor parcela'].replace({'R\\\\$': '', '\\\\.': '', ',': '.'}, regex=True).astype(float)\n",
    "\n",
    "# Converte a coluna de data e remove a hora\n",
    "df['Data do Pagamento'] = pd.to_datetime(df['Data do Pagamento']).dt.date\n",
    "\n",
    "# Cria conexão com banco de dados SQLite\n",
    "engine2 = create_engine(f\"sqlite:///{base2['db_path']}\")\n",
    "\n",
    "# Insere a tabela no banco\n",
    "df.to_sql(\"b_vendas_clientes_consigcar\", con=engine2, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed8c3380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp\n",
    "# Configurações das engines (base1 e base2)\n",
    "engine_base1 = create_engine(f\"sqlite:///{base1['db_path']}\")\n",
    "engine_base2 = create_engine(f\"sqlite:///{base2['db_path']}\")\n",
    "\n",
    "# Obter tabelas\n",
    "with engine_base1.connect() as conn:\n",
    "    tables_base1 = [table[0] for table in conn.execute(text(\"SELECT name FROM sqlite_master WHERE type='table'\"))]\n",
    "\n",
    "with engine_base2.connect() as conn:\n",
    "    tables_base2 = [table[0] for table in conn.execute(text(\"SELECT name FROM sqlite_master WHERE type='table'\"))]\n",
    "\n",
    "now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Processar base1\n",
    "with engine_base1.connect() as conn:\n",
    "    for table in tables_base1:\n",
    "        # Verificar se a coluna 'timestamp' existe\n",
    "        columns = [col[0] for col in conn.execute(text(f'PRAGMA table_info(\"{table}\")'))]\n",
    "        if 'timestamp' not in columns:\n",
    "            conn.execute(text(f'ALTER TABLE \"{table}\" ADD COLUMN timestamp TEXT DEFAULT \"{now}\"'))\n",
    "        else:\n",
    "            conn.execute(text(f'UPDATE \"{table}\" SET timestamp = :now WHERE timestamp IS NULL'), {'now': now})\n",
    "        conn.commit()  # Persistir as alterações\n",
    "\n",
    "# Processar base2 (mesma lógica)\n",
    "with engine_base2.connect() as conn:\n",
    "    for table in tables_base2:\n",
    "        columns = [col[0] for col in conn.execute(text(f'PRAGMA table_info(\"{table}\")'))]\n",
    "        if 'timestamp' not in columns:\n",
    "            conn.execute(text(f'ALTER TABLE \"{table}\" ADD COLUMN timestamp TEXT DEFAULT \"{now}\"'))\n",
    "        else:\n",
    "            conn.execute(text(f'UPDATE \"{table}\" SET timestamp = :now WHERE timestamp IS NULL'), {'now': now})\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd61f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar os bancos de dados em DBML para acompanhamento da modelagem\n",
    "dbml = sql_to_dbml(engine2)\n",
    "\n",
    "with open(base2[\"dbml_path\"], \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(dbml)\n",
    "\n",
    "dbml = sql_to_dbml(engine1)\n",
    "\n",
    "with open(base1[\"dbml_path\"], \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(dbml)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
